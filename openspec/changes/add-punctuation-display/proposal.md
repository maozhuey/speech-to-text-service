# 提案：增加标点符号实时显示

## 概述

为语音转文本服务添加实时标点符号显示功能，在用户说话过程中实时显示带有临时标点的中间识别结果，提升用户体验。

## 背景

**当前行为：**
- 前端 `updateInterimText()` 方法为空（暂时简化处理）
- 后端只返回 `is_final: True` 的最终结果
- 用户需要等待整句识别完成后才能看到文本

**痛点：**
- 用户在说话时看不到任何反馈
- 无法确认系统是否正常工作
- 缺乏实时交互感

## 目标

1. 实现前端实时显示中间识别结果（带临时标点）
2. 后端支持流式识别，返回中间结果
3. 最终结果替换中间结果，显示完整标点

## 非目标

- 不支持标点符号编辑
- 不修改后端标点恢复逻辑
- 不改变现有的断句机制

## 成功标准

1. 用户说话时能看到实时文本更新
2. 中间结果显示灰色或特殊样式，与最终结果区分
3. 最终结果带有完整标点符号
4. 实时延迟 < 500ms

## 影响范围

- **前端**: 实现 `updateInterimText()` 方法
- **后端**: FunASR流式识别支持（如支持）
- **WebSocket**: 消息格式支持中间结果

## 依赖项

- FunASR模型支持流式识别（需验证）
- 现有VAD断句功能

## 风险与缓解

| 风险 | 影响 | 缓解措施 |
|------|------|----------|
| FunASR不支持流式识别 | 中 | 回退到整句识别，前端用加载动画提示 |
| 实时显示增加前端复杂度 | 低 | 复用现有显示逻辑，仅添加样式区分 |
| 标点位置在中间结果不稳定 | 低 | 最终结果覆盖中间结果 |

## 待确认事项

1. FunASR是否支持流式识别返回中间结果？
2. 中间结果的标点准确性如何？
3. 实时更新的频率（每100ms？200ms？）

## 相关变更

- 依赖: `add-vad-based-segmentation` (VAD智能断句)
- 相关: `complete-funasr-integration` (FunASR集成)
